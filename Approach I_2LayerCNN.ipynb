{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final2LayerCNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Folder Split\n"
      ],
      "metadata": {
        "id": "aXqqjHknHUrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output_folder\n"
      ],
      "metadata": {
        "id": "pCL45Y6tHaz3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/charts.zip\" -d \"/content/output_folder\""
      ],
      "metadata": {
        "id": "vtYzlyEKw8XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0oTLyeeVaOr",
        "outputId": "47985e93-c43c-4f4b-b97f-3661aa3e4c25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "m6Ht6fBkxoBn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/output_folder/charts/train_val.csv', sep=\",\", names=['image_index','type'])\n",
        "\n"
      ],
      "metadata": {
        "id": "XR7fA4KLxoSz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df.iloc[1:,:].sort_values('type')\n",
        "class_names = list(labels.type.unique())\n"
      ],
      "metadata": {
        "id": "McgSmcZCyTev"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbqgh3b5_rPj",
        "outputId": "f78d5f91-31d5-421a-9e3f-8e2892bcc231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dot_line', 'hbar_categorical', 'line', 'pie', 'vbar_categorical']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''l=list(labels[labels['type']==c]['image_index'])'''"
      ],
      "metadata": {
        "id": "C2EH42Ik3w_m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4592dfaa-cc98-4387-81ca-be27d2683d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"l=list(labels[labels['type']==c]['image_index'])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''for c in class_names:\n",
        "    for i in l:\n",
        "      print(i+'.png')\n",
        "'''"
      ],
      "metadata": {
        "id": "hpYhY9oJ33wq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "383607a7-f31c-4bfa-b789-658a040c9885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"for c in class_names:\\n    for i in l:\\n      print(i+'.png')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in class_names:\n",
        "    os.makedirs(os.path.join('test_',i))\n"
      ],
      "metadata": {
        "id": "XNKQHZH6_IhF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''for c in class_names:\n",
        "  print(c)'''"
      ],
      "metadata": {
        "id": "jEgpgrhJAiuq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f0f2e3f7-7341-4080-957e-230f0815022a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for c in class_names:\\n  print(c)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in class_names:\n",
        "    for i in list(labels[labels['type']==c]['image_index']):\n",
        "\n",
        "        #create path to the image \n",
        "        i=i+'.png'\n",
        "        #print(i)\n",
        "        get_image = os.path.join('/content/output_folder/charts/train_val',i)\n",
        "\n",
        "        #If image has not already exist in the new folder create one        \n",
        "        if not os.path.exists('test_/'+c+i):\n",
        "            # move the image \n",
        "            move_image_to_cat = shutil.move(get_image,'test_/'+c)"
      ],
      "metadata": {
        "id": "pusyLMkFyqOD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in class_names:\n",
        "    print (c)\n",
        "    for i in list(labels[labels['type']==c]['image_index']):\n",
        "      print(i)"
      ],
      "metadata": {
        "id": "qlH6ToUiAp0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "im = cv2.imread('/content/test_/dot_line/800.png')\n",
        "\n",
        "print(type(im))\n",
        "# <class 'numpy.ndarray'>\n",
        "\n",
        "print(im.shape)\n",
        "print(type(im.shape))\n",
        "# (225, 400, 3)\n",
        "# <class 'tuple'>"
      ],
      "metadata": {
        "id": "x35thZr-dxZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2792702f-bf69-4b93-d5df-f405bb4982b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(128, 128, 3)\n",
            "<class 'tuple'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator"
      ],
      "metadata": {
        "id": "j0VFP-eFHdBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "HqV0Ujb0f4UQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "train_dir='/content/test_/'\n",
        "file_ = []\n",
        "for i in range(5) :\n",
        "    imfile = glob.glob(train_dir+class_names[i]+'/*.png')\n",
        "    file_ += [len(imfile)]\n",
        "\n",
        "(file_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Vbc6c1Hh7T",
        "outputId": "c52af451-d643-40f8-91f5-c500adddf6d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[200, 200, 200, 200, 200]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (9,6))\n",
        "bx = fig.add_subplot()\n",
        "bx.bar(class_names,file_)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "OuLY0gdcK7m0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "de0a589b-a9f1-4be7-a6de-87ef4897e135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport matplotlib.pyplot as plt\\nfig = plt.figure(figsize = (9,6))\\nbx = fig.add_subplot()\\nbx.bar(class_names,file_)\\nplt.xticks(rotation = 90)\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir train\n",
        "import tensorflow as tf\n",
        "save_dir_new='/content/train'"
      ],
      "metadata": {
        "id": "f9RIcKFkLd3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "ScaleTo=128\n",
        "ds_gen = ImageDataGenerator(\n",
        "    validation_split=0.2 ,rescale=1. / 255\n",
        ")\n",
        "\n",
        "train_ds = ds_gen.flow_from_directory(\n",
        "  \"/content/test_/\", \n",
        "  seed=1,\n",
        "  \n",
        "  target_size=(ScaleTo, ScaleTo), #adjust to your needs\n",
        "  batch_size=32,#adjust to your needs\n",
        "  class_mode='categorical',\n",
        "  subset='training' \n",
        ")\n",
        "\n",
        "val_ds = ds_gen.flow_from_directory(\n",
        "  \"/content/test_/\",\n",
        "  seed=1,\n",
        "  target_size=(ScaleTo, ScaleTo),\n",
        "  batch_size=32,\n",
        "  class_mode='categorical',\n",
        "  subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy2pQHsuaNbG",
        "outputId": "24d616ff-574a-4e42-84df-6bff9eaeea32"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 5 classes.\n",
            "Found 200 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "        validation_split=0.05,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.10,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "im_shape=(128,128)\n",
        "BATCH_SIZE = 16\n",
        "val_data_generator = ImageDataGenerator(validation_split=0.2)\n",
        "train_generator = data_generator.flow_from_directory('/content/test_/',target_size=im_shape, shuffle=True, \n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n",
        "# Generator para parte validação\n",
        "validation_generator = val_data_generator.flow_from_directory('/content/test_/',target_size=im_shape, shuffle=False, \n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n",
        "\n",
        "# Generator para dataset de teste\n",
        "test_generator = ImageDataGenerator()\n",
        "test_generator = test_generator.flow_from_directory('/content/output_folder/charts/',target_size=im_shape,classes=['test'], shuffle=False,\n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n",
        "\n",
        "nb_train_samples = train_generator.samples\n",
        "nb_validation_samples = validation_generator.samples\n",
        "nb_test_samples = test_generator.samples\n",
        "classes = list(train_generator.class_indices.keys())\n",
        "print('Classes: '+str(classes))\n",
        "num_classes  = len(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKjk2WtCLii3",
        "outputId": "cb7f5da0-8440-4d1e-bb6a-1258ea0ce4da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 950 images belonging to 5 classes.\n",
            "Found 200 images belonging to 5 classes.\n",
            "Found 50 images belonging to 1 classes.\n",
            "Classes: ['dot_line', 'hbar_categorical', 'line', 'pie', 'vbar_categorical']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "gUfIZmxEBL7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,Dense,MaxPool2D,Flatten\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "Uh5kGat6PQ8o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, padding = \"same\",activation = \"relu\",kernel_size=3, strides = 2,input_shape=(128,128,3)))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides = 2))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "\n",
        "model.add(Conv2D(filters = 32, padding = \"same\",activation = \"relu\",kernel_size=3))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides = 2))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(5,kernel_regularizer = l2(0.01),activation= \"softmax\"))\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "wX2FfNEg_Ie-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "vuvHojjCRZ5r",
        "outputId": "4a9bfdc5-46ec-4c3c-a3f2-ec9242005436",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1048704   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,059,749\n",
            "Trainable params: 1,059,621\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "# learning rate reduction\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.4, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "# checkpoints\n",
        "filepath=\"drive/DataScience/PlantReco/weights.best_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', \n",
        "                             verbose=1, save_best_only=True, mode='max')\n",
        "filepath=\"drive/DataScience/PlantReco/weights.last_auto4.hdf5\"\n",
        "checkpoint_all = ModelCheckpoint(filepath, monitor='val_accuracy', \n",
        "                                 verbose=1, save_best_only=False, mode='max')\n",
        "\n",
        "# all callbacks\n",
        "callbacks_list = [ learning_rate_reduction]\n",
        "'''"
      ],
      "metadata": {
        "id": "PJvHdrvOPpRA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "be046577-264a-461a-ee27-d353629a07ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\\n\\n# learning rate reduction\\nlearning_rate_reduction = ReduceLROnPlateau(monitor=\\'val_accuracy\\', \\n                                            patience=3, \\n                                            verbose=1, \\n                                            factor=0.4, \\n                                            min_lr=0.00001)\\n\\n# checkpoints\\nfilepath=\"drive/DataScience/PlantReco/weights.best_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\\ncheckpoint = ModelCheckpoint(filepath, monitor=\\'val_accuracy\\', \\n                             verbose=1, save_best_only=True, mode=\\'max\\')\\nfilepath=\"drive/DataScience/PlantReco/weights.last_auto4.hdf5\"\\ncheckpoint_all = ModelCheckpoint(filepath, monitor=\\'val_accuracy\\', \\n                                 verbose=1, save_best_only=False, mode=\\'max\\')\\n\\n# all callbacks\\ncallbacks_list = [ learning_rate_reduction]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.4, \n",
        "                                            min_lr=0.00001)\n",
        "BATCH_SIZE = 16\n",
        "# Saving the best model\n",
        "callbacks_list = [learning_rate_reduction,\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='model.h5',\n",
        "        monitor='val_loss', save_best_only=True, verbose=1),\n",
        "   # keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=nb_train_samples // BATCH_SIZE,\n",
        "        epochs=epochs,\n",
        "        callbacks = callbacks_list,\n",
        "        validation_data=validation_generator,\n",
        "        verbose = 1,\n",
        "        validation_steps=nb_validation_samples // BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V2-ck-jDjWr",
        "outputId": "4a9a69f5-70ba-4352-9a07-78513ecd948d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9850\n",
            "Epoch 1: val_loss improved from inf to 0.06669, saving model to model.h5\n",
            "59/59 [==============================] - 4s 76ms/step - loss: 0.0841 - accuracy: 0.9850 - val_loss: 0.0667 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 2/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9872\n",
            "Epoch 2: val_loss did not improve from 0.06669\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 0.0823 - accuracy: 0.9872 - val_loss: 0.3437 - val_accuracy: 0.9323 - lr: 1.0000e-05\n",
            "Epoch 3/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9893\n",
            "Epoch 3: val_loss did not improve from 0.06669\n",
            "59/59 [==============================] - 4s 74ms/step - loss: 0.0711 - accuracy: 0.9893 - val_loss: 0.1966 - val_accuracy: 0.9531 - lr: 1.0000e-05\n",
            "Epoch 4/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9797\n",
            "Epoch 4: val_loss improved from 0.06669 to 0.05274, saving model to model.h5\n",
            "59/59 [==============================] - 4s 71ms/step - loss: 0.0982 - accuracy: 0.9797 - val_loss: 0.0527 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 5/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9893\n",
            "Epoch 5: val_loss did not improve from 0.05274\n",
            "59/59 [==============================] - 4s 71ms/step - loss: 0.0841 - accuracy: 0.9893 - val_loss: 0.5022 - val_accuracy: 0.8906 - lr: 1.0000e-05\n",
            "Epoch 6/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9861\n",
            "Epoch 6: val_loss did not improve from 0.05274\n",
            "59/59 [==============================] - 4s 71ms/step - loss: 0.0992 - accuracy: 0.9861 - val_loss: 0.1276 - val_accuracy: 0.9740 - lr: 1.0000e-05\n",
            "Epoch 7/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9904\n",
            "Epoch 7: val_loss did not improve from 0.05274\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.0717 - accuracy: 0.9904 - val_loss: 0.3699 - val_accuracy: 0.9219 - lr: 1.0000e-05\n",
            "Epoch 8/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9893\n",
            "Epoch 8: val_loss did not improve from 0.05274\n",
            "59/59 [==============================] - 4s 71ms/step - loss: 0.0750 - accuracy: 0.9893 - val_loss: 0.0725 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
            "Epoch 9/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9925\n",
            "Epoch 9: val_loss improved from 0.05274 to 0.05211, saving model to model.h5\n",
            "59/59 [==============================] - 4s 74ms/step - loss: 0.0728 - accuracy: 0.9925 - val_loss: 0.0521 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 10/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9872\n",
            "Epoch 10: val_loss did not improve from 0.05211\n",
            "59/59 [==============================] - 4s 72ms/step - loss: 0.0870 - accuracy: 0.9872 - val_loss: 0.0875 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
            "Epoch 11/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9882\n",
            "Epoch 11: val_loss did not improve from 0.05211\n",
            "59/59 [==============================] - 4s 72ms/step - loss: 0.0692 - accuracy: 0.9882 - val_loss: 0.0553 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 12/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9850\n",
            "Epoch 12: val_loss did not improve from 0.05211\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.0875 - accuracy: 0.9850 - val_loss: 0.1451 - val_accuracy: 0.9635 - lr: 1.0000e-05\n",
            "Epoch 13/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9946\n",
            "Epoch 13: val_loss did not improve from 0.05211\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.0615 - accuracy: 0.9946 - val_loss: 0.0674 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
            "Epoch 14/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9829\n",
            "Epoch 14: val_loss improved from 0.05211 to 0.05174, saving model to model.h5\n",
            "59/59 [==============================] - 4s 75ms/step - loss: 0.0968 - accuracy: 0.9829 - val_loss: 0.0517 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 15/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9797\n",
            "Epoch 15: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 74ms/step - loss: 0.0951 - accuracy: 0.9797 - val_loss: 0.1157 - val_accuracy: 0.9740 - lr: 1.0000e-05\n",
            "Epoch 16/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9861\n",
            "Epoch 16: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 72ms/step - loss: 0.0838 - accuracy: 0.9861 - val_loss: 0.0732 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 17/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9786\n",
            "Epoch 17: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 71ms/step - loss: 0.0893 - accuracy: 0.9786 - val_loss: 0.0744 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
            "Epoch 18/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9839\n",
            "Epoch 18: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 71ms/step - loss: 0.0821 - accuracy: 0.9839 - val_loss: 0.0688 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
            "Epoch 19/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9872\n",
            "Epoch 19: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 71ms/step - loss: 0.0885 - accuracy: 0.9872 - val_loss: 0.2357 - val_accuracy: 0.9479 - lr: 1.0000e-05\n",
            "Epoch 20/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9754\n",
            "Epoch 20: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.1089 - accuracy: 0.9754 - val_loss: 0.3771 - val_accuracy: 0.9271 - lr: 1.0000e-05\n",
            "Epoch 21/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9946\n",
            "Epoch 21: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 72ms/step - loss: 0.0667 - accuracy: 0.9946 - val_loss: 0.1605 - val_accuracy: 0.9635 - lr: 1.0000e-05\n",
            "Epoch 22/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9893\n",
            "Epoch 22: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 6s 100ms/step - loss: 0.0812 - accuracy: 0.9893 - val_loss: 0.2177 - val_accuracy: 0.9635 - lr: 1.0000e-05\n",
            "Epoch 23/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9818\n",
            "Epoch 23: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.0921 - accuracy: 0.9818 - val_loss: 0.0589 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 24/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9914\n",
            "Epoch 24: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 74ms/step - loss: 0.0663 - accuracy: 0.9914 - val_loss: 0.0524 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 25/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9872\n",
            "Epoch 25: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 74ms/step - loss: 0.0741 - accuracy: 0.9872 - val_loss: 0.0537 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 26/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9861\n",
            "Epoch 26: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.0858 - accuracy: 0.9861 - val_loss: 0.0612 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 27/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9872\n",
            "Epoch 27: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.0777 - accuracy: 0.9872 - val_loss: 0.0536 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 28/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9882\n",
            "Epoch 28: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 75ms/step - loss: 0.0748 - accuracy: 0.9882 - val_loss: 0.0523 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 29/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9893\n",
            "Epoch 29: val_loss did not improve from 0.05174\n",
            "59/59 [==============================] - 4s 72ms/step - loss: 0.0890 - accuracy: 0.9893 - val_loss: 0.0838 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
            "Epoch 30/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9882\n",
            "Epoch 30: val_loss improved from 0.05174 to 0.05145, saving model to model.h5\n",
            "59/59 [==============================] - 4s 74ms/step - loss: 0.0784 - accuracy: 0.9882 - val_loss: 0.0515 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 31/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9893\n",
            "Epoch 31: val_loss did not improve from 0.05145\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.0711 - accuracy: 0.9893 - val_loss: 0.0571 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 32/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9872\n",
            "Epoch 32: val_loss did not improve from 0.05145\n",
            "59/59 [==============================] - 4s 74ms/step - loss: 0.0955 - accuracy: 0.9872 - val_loss: 0.0790 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
            "Epoch 33/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9852\n",
            "Epoch 33: val_loss did not improve from 0.05145\n",
            "59/59 [==============================] - 4s 72ms/step - loss: 0.0883 - accuracy: 0.9852 - val_loss: 0.0674 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 34/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9882\n",
            "Epoch 34: val_loss improved from 0.05145 to 0.05057, saving model to model.h5\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.0770 - accuracy: 0.9882 - val_loss: 0.0506 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 35/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9861\n",
            "Epoch 35: val_loss did not improve from 0.05057\n",
            "59/59 [==============================] - 4s 74ms/step - loss: 0.0819 - accuracy: 0.9861 - val_loss: 0.0813 - val_accuracy: 0.9844 - lr: 1.0000e-05\n",
            "Epoch 36/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9936\n",
            "Epoch 36: val_loss did not improve from 0.05057\n",
            "59/59 [==============================] - 4s 72ms/step - loss: 0.0735 - accuracy: 0.9936 - val_loss: 0.0578 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
            "Epoch 37/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9872\n",
            "Epoch 37: val_loss did not improve from 0.05057\n",
            "59/59 [==============================] - 4s 74ms/step - loss: 0.0815 - accuracy: 0.9872 - val_loss: 0.0678 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 38/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9946\n",
            "Epoch 38: val_loss did not improve from 0.05057\n",
            "59/59 [==============================] - 4s 73ms/step - loss: 0.0663 - accuracy: 0.9946 - val_loss: 0.0533 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 39/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9914\n",
            "Epoch 39: val_loss did not improve from 0.05057\n",
            "59/59 [==============================] - 4s 71ms/step - loss: 0.0676 - accuracy: 0.9914 - val_loss: 0.0987 - val_accuracy: 0.9792 - lr: 1.0000e-05\n",
            "Epoch 40/40\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9904\n",
            "Epoch 40: val_loss did not improve from 0.05057\n",
            "59/59 [==============================] - 4s 71ms/step - loss: 0.0726 - accuracy: 0.9904 - val_loss: 0.0730 - val_accuracy: 0.9844 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluations/ prediction\n"
      ],
      "metadata": {
        "id": "onvgQRuhXEX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('No. of epochs')\n",
        "plt.ylabel('Losses')\n",
        "plt.legend(['Train','Validation'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('No. of epochs')\n",
        "plt.ylabel('accuracies')\n",
        "plt.legend(['Train','Validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YxP6zMthXJiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "        validation_split=0.05,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.10,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "im_shape=(128,128)\n",
        "BATCH_SIZE = 16\n",
        "val_data_generator = ImageDataGenerator(validation_split=0.2)\n",
        "train_generator = data_generator.flow_from_directory('/content/test_/',target_size=im_shape, shuffle=True, \n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n",
        "# Generator para parte validação\n",
        "validation_generator = val_data_generator.flow_from_directory('/content/test_/',target_size=im_shape, shuffle=False, \n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n",
        "\n",
        "# Generator para dataset de teste\n",
        "test_generator = ImageDataGenerator()\n",
        "test_generator = test_generator.flow_from_directory('/content/output_folder/charts/',target_size=im_shape,classes=['test'], shuffle=False,\n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n",
        "\n",
        "nb_train_samples = train_generator.samples\n",
        "nb_validation_samples = validation_generator.samples\n",
        "nb_test_samples = test_generator.samples\n",
        "classes = list(train_generator.class_indices.keys())\n",
        "print('Classes: '+str(classes))\n",
        "num_classes  = len(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiUzPS8hCs-r",
        "outputId": "e4cce1b0-a661-455d-fa0f-d5ba555c25b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 950 images belonging to 5 classes.\n",
            "Found 200 images belonging to 5 classes.\n",
            "Found 50 images belonging to 1 classes.\n",
            "Classes: ['dot_line', 'hbar_categorical', 'line', 'pie', 'vbar_categorical']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import resnet50\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, ReLU, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.activations import swish,relu\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from keras.utils import layer_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from statistics import mean\n",
        "import math\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False,title='Confusion matrix',cmap=plt.cm.Greens):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "4Oc-xhKvY25b"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#val\n",
        "import itertools\n",
        "predictions = model.predict_generator(validation_generator)\n",
        "y_predval_vgg = np.argmax(predictions, axis=1)\n",
        "cf_matrix = confusion_matrix(validation_generator.classes, y_predval_vgg)\n",
        "print('Classification Report')\n",
        "print(classification_report(validation_generator.classes, y_predval_vgg, target_names=class_names))\n",
        "#plt.figure(figsize=(20,20))\n",
        "confusionMTX = confusion_matrix(validation_generator.classes, y_predval_vgg) \n",
        "plot_confusion_matrix(confusionMTX, classes =class_names) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Saav4BMFVQa9",
        "outputId": "92d38501-43ee-4962-ce02-711b6996c72f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        dot_line       1.00      0.97      0.99        40\n",
            "hbar_categorical       1.00      1.00      1.00        40\n",
            "            line       0.98      1.00      0.99        40\n",
            "             pie       1.00      1.00      1.00        40\n",
            "vbar_categorical       1.00      1.00      1.00        40\n",
            "\n",
            "        accuracy                           0.99       200\n",
            "       macro avg       1.00      0.99      0.99       200\n",
            "    weighted avg       1.00      0.99      0.99       200\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_vgg = model.predict_generator(validation_generator)\n",
        "y_pred_vgg = np.argmax(Y_pred_vgg, axis=1)\n",
        "print('Confusion Matrix')\n",
        "conf_matrix_vgg = confusion_matrix(validation_generator.classes, y_pred_vgg)\n",
        "cm_vgg = np.array2string(conf_matrix_vgg)\n",
        "print(conf_matrix_vgg)\n",
        "print(\"=============================================================================================\")\n",
        "print('Classification Report')\n",
        "target_names = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9']\n",
        "class_rep_vgg = classification_report(validation_generator.classes, y_pred_vgg, target_names=class_names)\n",
        "#plot_confusion_matrix\n",
        "print(class_rep_vgg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEu9EyL99zB4",
        "outputId": "8df4d089-d897-4541-95d9-adab617d3187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[36  0  4  0  0]\n",
            " [ 0 39  0  0  1]\n",
            " [ 0  0 40  0  0]\n",
            " [ 0  0  0 40  0]\n",
            " [ 0  0  0  0 40]]\n",
            "=============================================================================================\n",
            "Classification Report\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        dot_line       1.00      0.90      0.95        40\n",
            "hbar_categorical       1.00      0.97      0.99        40\n",
            "            line       0.91      1.00      0.95        40\n",
            "             pie       1.00      1.00      1.00        40\n",
            "vbar_categorical       0.98      1.00      0.99        40\n",
            "\n",
            "        accuracy                           0.97       200\n",
            "       macro avg       0.98      0.97      0.97       200\n",
            "    weighted avg       0.98      0.97      0.97       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=model.predict_generator(test_generator, steps=len(test_generator))\n",
        "prediction.shape\n",
        "prediction_index= np.argmax(prediction, axis=1)\n",
        "prediction_index.shape\n",
        "(10000,)\n",
        "labels=train_ds.class_indices\n",
        "print(type(labels), len(labels))\n",
        "\n",
        "labels = dict((value,key) for key,value in labels.items())\n",
        "# labels\n",
        "predicted_class = [labels[k] for k in prediction_index]\n",
        "len(predicted_class)\n",
        "# predicted_class\n",
        "10000\n",
        "filenames_ = test_generator.filenames\n",
        "#filenames_\n",
        "\n",
        "filenames=[]\n",
        "\n",
        "for e in filenames_:\n",
        "    e = e[5:7]\n",
        "    filenames.append(e)\n",
        "results = pd.DataFrame({\"file_name\":filenames, \"category\":predicted_class})\n",
        "df =results.sort_values(by=[\"category\"])  # this  will sort the whole df in decending order on the basis of the column \"2\"\n",
        "\n",
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "88jbZqJTZbQ_",
        "outputId": "1c4372e0-d660-4f61-adcb-74db95a0e9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'> 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   file_name          category\n",
              "0         0.  vbar_categorical\n",
              "1         1.  hbar_categorical\n",
              "2         10          dot_line\n",
              "3         11  hbar_categorical\n",
              "4         12              line\n",
              "5         13              line\n",
              "6         14               pie\n",
              "7         15              line\n",
              "8         16  hbar_categorical\n",
              "9         17  vbar_categorical\n",
              "10        18          dot_line\n",
              "11        19  hbar_categorical\n",
              "12        2.  vbar_categorical\n",
              "13        20          dot_line\n",
              "14        21               pie\n",
              "15        22          dot_line\n",
              "16        23               pie\n",
              "17        24  vbar_categorical\n",
              "18        25  hbar_categorical\n",
              "19        26  hbar_categorical\n",
              "20        27          dot_line\n",
              "21        28               pie\n",
              "22        29               pie\n",
              "23        3.  vbar_categorical\n",
              "24        30  hbar_categorical\n",
              "25        31              line\n",
              "26        32  vbar_categorical\n",
              "27        33  hbar_categorical\n",
              "28        34  hbar_categorical\n",
              "29        35              line\n",
              "30        36  vbar_categorical\n",
              "31        37          dot_line\n",
              "32        38  vbar_categorical\n",
              "33        39          dot_line\n",
              "34        4.              line\n",
              "35        40              line\n",
              "36        41  vbar_categorical\n",
              "37        42               pie\n",
              "38        43  hbar_categorical\n",
              "39        44               pie\n",
              "40        45  hbar_categorical\n",
              "41        46              line\n",
              "42        47               pie\n",
              "43        48               pie\n",
              "44        49              line\n",
              "45        5.              line\n",
              "46        6.  vbar_categorical\n",
              "47        7.  vbar_categorical\n",
              "48        8.              line\n",
              "49        9.              line"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8d7ec01-6677-4733-a2b5-ca1890dc37e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>dot_line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>14</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>15</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>16</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>17</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>18</td>\n",
              "      <td>dot_line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>19</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2.</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>20</td>\n",
              "      <td>dot_line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>21</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>22</td>\n",
              "      <td>dot_line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>23</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>24</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>25</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>26</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>27</td>\n",
              "      <td>dot_line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>28</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>29</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3.</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>30</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>31</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>32</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>33</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>34</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>35</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>36</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>37</td>\n",
              "      <td>dot_line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>38</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>39</td>\n",
              "      <td>dot_line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>4.</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>40</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>41</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>42</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>43</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>44</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>45</td>\n",
              "      <td>hbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>46</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>47</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>48</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>49</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>5.</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>6.</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>7.</td>\n",
              "      <td>vbar_categorical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>8.</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>9.</td>\n",
              "      <td>line</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8d7ec01-6677-4733-a2b5-ca1890dc37e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8d7ec01-6677-4733-a2b5-ca1890dc37e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8d7ec01-6677-4733-a2b5-ca1890dc37e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###For above result refer the filename to column to validate"
      ],
      "metadata": {
        "id": "qX8XBFSCgXiY"
      }
    }
  ]
}